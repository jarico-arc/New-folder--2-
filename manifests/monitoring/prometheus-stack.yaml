# Comprehensive Prometheus Stack for YugabyteDB Monitoring
# Includes SLO burn-rate rules and custom dashboards

apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
    pod-security.kubernetes.io/enforce: restricted

---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: kube-prometheus-stack
    repoURL: https://prometheus-community.github.io/helm-charts
    targetRevision: "57.2.0"
    helm:
      values: |
        # Global configuration
        global:
          rbac:
            createAggregateClusterRoles: false
        
        # Prometheus configuration
        prometheus:
          prometheusSpec:
            retention: 30d
            retentionSize: "100GiB"
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: pd-ssd-regional
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 200Gi
            resources:
              requests:
                cpu: "2"
                memory: 8Gi
              limits:
                cpu: "4"
                memory: 16Gi
            # Service monitors for YugabyteDB
            serviceMonitorSelectorNilUsesHelmValues: false
            serviceMonitorSelector: {}
            podMonitorSelectorNilUsesHelmValues: false
            podMonitorSelector: {}
            # Additional scrape configs for YugabyteDB
            additionalScrapeConfigs:
              - job_name: 'yugabyte-master'
                kubernetes_sd_configs:
                  - role: pod
                    namespaces:
                      names: ['yb-prod', 'yb-staging', 'yb-dev']
                relabel_configs:
                  - source_labels: [__meta_kubernetes_pod_label_app]
                    action: keep
                    regex: yb-master
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                    action: keep
                    regex: true
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
                    action: replace
                    target_label: __address__
                    regex: (.+)
                    replacement: ${1}:9300
              - job_name: 'yugabyte-tserver'
                kubernetes_sd_configs:
                  - role: pod
                    namespaces:
                      names: ['yb-prod', 'yb-staging', 'yb-dev']
                relabel_configs:
                  - source_labels: [__meta_kubernetes_pod_label_app]
                    action: keep
                    regex: yb-tserver
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                    action: keep
                    regex: true
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
                    action: replace
                    target_label: __address__
                    regex: (.+)
                    replacement: ${1}:9000
        
        # Grafana configuration
        grafana:
          adminPassword: "admin123!"  # Change in production
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: "1"
              memory: 2Gi
          persistence:
            enabled: true
            storageClassName: pd-ssd-regional
            size: 10Gi
          # Custom dashboards for YugabyteDB
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
              - name: 'yugabyte'
                orgId: 1
                folder: 'YugabyteDB'
                type: file
                disableDeletion: false
                editable: true
                options:
                  path: /var/lib/grafana/dashboards/yugabyte
          dashboards:
            yugabyte:
              yugabyte-overview:
                gnetId: 12620
                revision: 1
                datasource: Prometheus
              yugabyte-cluster:
                gnetId: 12621  
                revision: 1
                datasource: Prometheus
          # Pre-configured data sources
          additionalDataSources:
            - name: Prometheus
              type: prometheus
              url: http://kube-prometheus-stack-prometheus:9090
              isDefault: true
        
        # AlertManager configuration
        alertmanager:
          alertmanagerSpec:
            storage:
              volumeClaimTemplate:
                spec:
                  storageClassName: pd-ssd-regional
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 10Gi
            resources:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                cpu: 500m
                memory: 512Mi
          config:
            global:
              smtp_smarthost: 'localhost:587'
              smtp_from: 'alertmanager@company.com'
            route:
              group_by: ['alertname', 'cluster', 'service']
              group_wait: 10s
              group_interval: 10s
              repeat_interval: 1h
              receiver: 'web.hook'
              routes:
              - match:
                  severity: critical
                receiver: 'pager'
              - match:
                  severity: warning
                receiver: 'slack'
            receivers:
            - name: 'web.hook'
              webhook_configs:
              - url: 'http://localhost:5001/webhook'
            - name: 'pager'
              webhook_configs:
              - url: 'https://events.pagerduty.com/v2/enqueue'
                http_config:
                  bearer_token: 'your-pagerduty-key'
            - name: 'slack'
              slack_configs:
              - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
                channel: '#alerts'
                title: 'YugabyteDB Alert'
                text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

---
# Custom ServiceMonitor for YugabyteDB
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: yugabyte-monitoring
  namespace: monitoring
  labels:
    app: yugabytedb
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app: yb-master
  namespaceSelector:
    matchNames:
    - yb-prod
    - yb-staging
    - yb-dev
  endpoints:
  - port: http-ui
    interval: 15s
    path: /prometheus-metrics
  - port: http-ycql-met
    interval: 15s
    path: /prometheus-metrics

---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: yugabyte-tserver-monitoring
  namespace: monitoring
  labels:
    app: yugabytedb
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app: yb-tserver
  namespaceSelector:
    matchNames:
    - yb-prod
    - yb-staging
    - yb-dev  
  endpoints:
  - port: http-ysql-met
    interval: 15s
    path: /prometheus-metrics
  - port: http-ycql-met
    interval: 15s
    path: /prometheus-metrics

---
# Redpanda ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: redpanda-monitoring
  namespace: monitoring
  labels:
    app: redpanda
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: redpanda
  namespaceSelector:
    matchNames:
    - kafka
  endpoints:
  - port: prometheus
    interval: 15s
    path: /metrics 