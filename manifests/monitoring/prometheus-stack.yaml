# Comprehensive Prometheus Stack for YugabyteDB Monitoring
# Security: No hardcoded passwords, secure defaults
# Includes SLO burn-rate rules and custom dashboards

apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted

---
# Secret for Grafana admin password - MUST be created separately
apiVersion: v1
kind: Secret
metadata:
  name: grafana-admin-secret
  namespace: monitoring
type: Opaque
data:
  # SECURITY: Admin password must be generated and set externally
  # Generate using: make generate-grafana-secret
  # Or manually: kubectl create secret generic grafana-admin-secret -n monitoring \
  #   --from-literal=admin-user=admin \
  #   --from-literal=admin-password="$(openssl rand -base64 32)"
  admin-user: YWRtaW4=  # admin (base64)
  admin-password: ""  # MUST be set via external secret management - DO NOT COMMIT

---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: kube-prometheus-stack
    repoURL: https://prometheus-community.github.io/helm-charts
    targetRevision: "57.2.0"
    helm:
      values: |
        # Global configuration with security hardening
        global:
          rbac:
            createAggregateClusterRoles: false
          imagePullSecrets: []
        
        # Enhanced exporters for comprehensive observability
        nodeExporter:
          enabled: true
          jobLabel: node-exporter
          serviceMonitor:
            enabled: true
            scrapeTimeout: 10s
            interval: 30s
        
        kubeStateMetrics:
          enabled: true
          metricLabelsAllowlist:
            - "persistentvolumes=[*]"
            - "persistentvolumeclaims=[*]"
            - "pods=[*]"
            - "nodes=[*]"
        
        # Prometheus configuration with enhanced security
        prometheus:
          prometheusSpec:
            retention: 30d
            retentionSize: "100GiB"
            # Security: Non-root container
            securityContext:
              runAsNonRoot: true
              runAsUser: 65534
              fsGroup: 65534
            # Resource management
            resources:
              requests:
                cpu: "2"
                memory: 8Gi
              limits:
                cpu: "4"
                memory: 16Gi
            # Persistent storage configuration
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: ssd-monitoring
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 200Gi
            # Service discovery configuration
            serviceMonitorSelectorNilUsesHelmValues: false
            serviceMonitorSelector: {}
            podMonitorSelectorNilUsesHelmValues: false
            podMonitorSelector: {}
            ruleSelectorNilUsesHelmValues: false
            ruleSelector: {}
            
            # Enhanced scrape configs for YugabyteDB multi-cluster
            additionalScrapeConfigs:
              - job_name: 'yugabyte-master-helm'
                scrape_interval: 30s
                scrape_timeout: 10s
                metrics_path: /prometheus-metrics
                kubernetes_sd_configs:
                  - role: pod
                    namespaces:
                      names: ['codet-dev-yb', 'codet-staging-yb', 'codet-prod-yb']
                relabel_configs:
                  - source_labels: [__meta_kubernetes_pod_label_app]
                    action: keep
                    regex: yb-master
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                    action: keep
                    regex: true
                  - source_labels: [__meta_kubernetes_pod_ip]
                    action: replace
                    target_label: __address__
                    regex: (.+)
                    replacement: ${1}:7000
                  - source_labels: [__meta_kubernetes_namespace]
                    action: replace
                    target_label: kubernetes_namespace
                  - source_labels: [__meta_kubernetes_pod_name]
                    action: replace
                    target_label: kubernetes_pod_name
                    
              - job_name: 'yugabyte-tserver-helm'
                scrape_interval: 30s
                scrape_timeout: 10s
                metrics_path: /prometheus-metrics
                kubernetes_sd_configs:
                  - role: pod
                    namespaces:
                      names: ['codet-dev-yb', 'codet-staging-yb', 'codet-prod-yb']
                relabel_configs:
                  - source_labels: [__meta_kubernetes_pod_label_app]
                    action: keep
                    regex: yb-tserver
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                    action: keep
                    regex: true
                  - source_labels: [__meta_kubernetes_pod_ip]
                    action: replace
                    target_label: __address__
                    regex: (.+)
                    replacement: ${1}:9000
                  - source_labels: [__meta_kubernetes_namespace]
                    action: replace
                    target_label: kubernetes_namespace
                  - source_labels: [__meta_kubernetes_pod_name]
                    action: replace
                    target_label: kubernetes_pod_name

              # Kubelet volume stats for disk usage monitoring
              - job_name: 'kubelet-volume-stats'
                scrape_interval: 60s
                scrape_timeout: 10s
                metrics_path: /metrics/resource
                scheme: https
                bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
                tls_config:
                  ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                  insecure_skip_verify: true
                kubernetes_sd_configs:
                  - role: node
                relabel_configs:
                  - action: labelmap
                    regex: __meta_kubernetes_node_label_(.+)
                  - target_label: __address__
                    replacement: kubernetes.default.svc:443
                  - source_labels: [__meta_kubernetes_node_name]
                    regex: (.+)
                    target_label: __metrics_path__
                    replacement: /api/v1/nodes/${1}/proxy/metrics/resource

              # PostgreSQL stats for client activity monitoring
              - job_name: 'postgres-exporter'
                scrape_interval: 60s
                kubernetes_sd_configs:
                  - role: service
                    namespaces:
                      names: ['codet-dev-yb', 'codet-staging-yb', 'codet-prod-yb']
                relabel_configs:
                  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
                    action: keep
                    regex: true
                  - source_labels: [__meta_kubernetes_service_label_app]
                    action: keep
                    regex: postgres-exporter
        
        # Grafana configuration with security improvements
        grafana:
          # Security: Use external secret for admin password
          admin:
            existingSecret: grafana-admin-secret
            userKey: admin-user
            passwordKey: admin-password
          
          # Security context
          securityContext:
            runAsNonRoot: true
            runAsUser: 472
            fsGroup: 472
          
          # Resource management
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: "1"
              memory: 2Gi
          
          # Persistent storage
          persistence:
            enabled: true
            storageClassName: ssd-monitoring
            size: 10Gi
            accessModes:
              - ReadWriteOnce
          
          # Security: Disable anonymous access
          grafana.ini:
            security:
              disable_initial_admin_creation: false
              admin_user: admin
              cookie_secure: true
              cookie_samesite: strict
            auth.anonymous:
              enabled: false
            auth:
              disable_login_form: false
            server:
              protocol: http
              enforce_domain: false
              root_url: ""
          
          # Pre-configured dashboards for YugabyteDB
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
              - name: 'yugabyte'
                orgId: 1
                folder: 'YugabyteDB'
                type: file
                disableDeletion: false
                editable: true
                options:
                  path: /var/lib/grafana/dashboards/yugabyte
              - name: 'kubernetes'
                orgId: 1
                folder: 'Kubernetes'
                type: file
                disableDeletion: false
                editable: true
                options:
                  path: /var/lib/grafana/dashboards/kubernetes
              - name: 'infrastructure'
                orgId: 1
                folder: 'Infrastructure'
                type: file
                disableDeletion: false
                editable: true
                options:
                  path: /var/lib/grafana/dashboards/infrastructure

          # Enhanced dashboard configuration maps
          dashboards:
            yugabyte:
              yugabytedb-cluster-overview:
                file: dashboards/yugabytedb-cluster-overview.json
              yugabytedb-client-activity:
                gnetId: 17945
                revision: 1
                datasource: Prometheus
            kubernetes:
              kubernetes-infrastructure:
                file: dashboards/kubernetes-infrastructure.json
              persistent-volumes:
                gnetId: 13646
                revision: 2
                datasource: Prometheus
            infrastructure:
              node-exporter:
                gnetId: 1860
                revision: 37
                datasource: Prometheus
              disk-health:
                gnetId: 10664
                revision: 1
                datasource: Prometheus

        # Alertmanager configuration
        alertmanager:
          alertmanagerSpec:
            securityContext:
              runAsNonRoot: true
              runAsUser: 65534
              fsGroup: 65534
            resources:
              requests:
                cpu: 100m
                memory: 128Mi
              limits:
                cpu: 200m
                memory: 256Mi
            storage:
              volumeClaimTemplate:
                spec:
                  storageClassName: ssd-monitoring
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 5Gi
            # External configuration from ConfigMap
            configSecret: alertmanager-config

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true

---
# Service Monitor for YugabyteDB Master nodes
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: yugabytedb-master
  namespace: monitoring
  labels:
    app: yugabytedb
    component: master
spec:
  selector:
    matchLabels:
      app: yb-masters
  namespaceSelector:
    matchNames:
      - codet-dev-yb
      - codet-staging-yb
      - codet-prod-yb
  endpoints:
  - port: ui
    path: /prometheus-metrics
    interval: 30s
    scrapeTimeout: 10s

---
# Service Monitor for YugabyteDB TServer nodes
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: yugabytedb-tserver
  namespace: monitoring
  labels:
    app: yugabytedb
    component: tserver
spec:
  selector:
    matchLabels:
      app: yb-tservers
  namespaceSelector:
    matchNames:
      - codet-dev-yb
      - codet-staging-yb
      - codet-prod-yb
  endpoints:
  - port: ui
    path: /prometheus-metrics
    interval: 30s
    scrapeTimeout: 10s

---
# SMART monitoring DaemonSet for disk health
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: smartmon-exporter
  namespace: monitoring
  labels:
    app: smartmon-exporter
spec:
  selector:
    matchLabels:
      app: smartmon-exporter
  template:
    metadata:
      labels:
        app: smartmon-exporter
    spec:
      hostNetwork: true
      hostPID: true
      containers:
      - name: smartmon-exporter
        image: prometheuscommunity/smartctl-exporter:v0.12.0
        args:
          - --smartctl.path=/usr/sbin/smartctl
          - --smartctl.interval=60s
          - --web.listen-address=:9633
        ports:
        - containerPort: 9633
          hostPort: 9633
          name: metrics
        securityContext:
          privileged: true
        volumeMounts:
        - name: dev
          mountPath: /dev
          readOnly: true
        - name: smart
          mountPath: /usr/sbin/smartctl
          readOnly: true
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 100m
            memory: 128Mi
      volumes:
      - name: dev
        hostPath:
          path: /dev
      - name: smart
        hostPath:
          path: /usr/sbin/smartctl
      tolerations:
      - effect: NoSchedule
        operator: Exists
      - effect: NoExecute
        operator: Exists

---
# Service for SMART monitoring
apiVersion: v1
kind: Service
metadata:
  name: smartmon-exporter
  namespace: monitoring
  labels:
    app: smartmon-exporter
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9633"
spec:
  type: ClusterIP
  ports:
  - port: 9633
    targetPort: 9633
    name: metrics
  selector:
    app: smartmon-exporter

---
# Service Monitor for SMART data
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: smartmon-exporter
  namespace: monitoring
  labels:
    app: smartmon-exporter
spec:
  selector:
    matchLabels:
      app: smartmon-exporter
  endpoints:
  - port: metrics
    interval: 60s
    path: /metrics 