# Prometheus Alert Rules for YugabyteDB
# This file defines alerting rules for monitoring YugabyteDB health and performance

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: yugabytedb-alert-rules
  namespace: monitoring
  labels:
    app: prometheus
data:
  yugabytedb.yml: |
    groups:
    - name: yugabytedb.rules
      rules:
      # Master Node Alerts
      - alert: YBMasterDown
        expr: up{job="yugabytedb-master"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "YugabyteDB Master node is down"
          description: "YugabyteDB Master node {{ $labels.instance }} in namespace {{ $labels.namespace }} has been down for more than 1 minute."

      - alert: YBMasterQuorumLost
        expr: sum(up{job="yugabytedb-master"}) by (namespace) < 2
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "YugabyteDB Master quorum lost"
          description: "YugabyteDB Master quorum lost in namespace {{ $labels.namespace }}. Only {{ $value }} masters are available."

      # TServer Node Alerts
      - alert: YBTServerDown
        expr: up{job="yugabytedb-tserver"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB TServer node is down"
          description: "YugabyteDB TServer node {{ $labels.instance }} in namespace {{ $labels.namespace }} has been down for more than 2 minutes."

      - alert: YBTServerCriticallyLow
        expr: sum(up{job="yugabytedb-tserver"}) by (namespace) < 2
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "YugabyteDB TServer count critically low"
          description: "Only {{ $value }} TServer nodes available in namespace {{ $labels.namespace }}. This may affect data availability."

      # Resource Usage Alerts
      - alert: YBHighCPUUsage
        expr: (rate(cpu_usage_user{job="yugabytedb-tserver"}[5m]) + rate(cpu_usage_system{job="yugabytedb-tserver"}[5m])) > 0.8
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB high CPU usage"
          description: "YugabyteDB TServer {{ $labels.instance }} CPU usage is above 80% for more than 10 minutes."

      - alert: YBHighMemoryUsage
        expr: memory_usage{job="yugabytedb-tserver"} / memory_limit{job="yugabytedb-tserver"} > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB high memory usage"
          description: "YugabyteDB TServer {{ $labels.instance }} memory usage is above 90% for more than 5 minutes."

      # Connection Alerts
      - alert: YBHighConnectionCount
        expr: yb_node_connections{job="yugabytedb-tserver"} > 100
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB high connection count"
          description: "YugabyteDB TServer {{ $labels.instance }} has more than 100 connections for 15 minutes."

      # Disk Usage Alerts
      - alert: YBHighDiskUsage
        expr: disk_usage_percent{job="yugabytedb-tserver"} > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB high disk usage"
          description: "YugabyteDB TServer {{ $labels.instance }} disk usage is above 85%."

      - alert: YBCriticalDiskUsage
        expr: disk_usage_percent{job="yugabytedb-tserver"} > 95
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "YugabyteDB critical disk usage"
          description: "YugabyteDB TServer {{ $labels.instance }} disk usage is above 95%. Immediate action required."

      # Replication Lag Alerts
      - alert: YBHighReplicationLag
        expr: replication_lag_ms{job="yugabytedb-tserver"} > 10000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB high replication lag"
          description: "YugabyteDB replication lag is higher than 10 seconds on {{ $labels.instance }}."

      # Cluster Health Alerts
      - alert: YBClusterUnhealthy
        expr: cluster_health_status{job="yugabytedb-master"} != 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "YugabyteDB cluster is unhealthy"
          description: "YugabyteDB cluster in namespace {{ $labels.namespace }} is reporting unhealthy status."

      # Network Partition Alerts
      - alert: YBNetworkPartition
        expr: increase(network_errors_total{job="yugabytedb-tserver"}[5m]) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB network errors detected"
          description: "YugabyteDB TServer {{ $labels.instance }} is experiencing network errors. This may indicate network partition."

    # General Kubernetes Alerts for YugabyteDB
    - name: yugabytedb-kubernetes.rules
      rules:
      - alert: YBPodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total{container=~"yb-.*"}[15m]) > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "YugabyteDB pod is crash looping"
          description: "YugabyteDB pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crash looping."

      - alert: YBPodNotReady
        expr: kube_pod_status_ready{condition="false", pod=~".*yb.*"} == 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB pod not ready"
          description: "YugabyteDB pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been not ready for more than 10 minutes."

      - alert: YBPersistentVolumeClaimPending
        expr: kube_persistentvolumeclaim_status_phase{phase="Pending", persistentvolumeclaim=~".*yb.*"} == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "YugabyteDB PVC is pending"
          description: "PersistentVolumeClaim {{ $labels.persistentvolumeclaim }} for YugabyteDB in namespace {{ $labels.namespace }} is pending."

---
# AlertManager Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alertmanager@codet.com'
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'default'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
      - match:
          environment: production
        receiver: 'production-alerts'
    
    receivers:
    - name: 'default'
      webhook_configs:
      - url: 'http://localhost:5001/webhook'
        send_resolved: true
    
    - name: 'critical-alerts'
      email_configs:
      - to: 'admin@codet.com'
        subject: 'CRITICAL: YugabyteDB Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Description: {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
          
    - name: 'production-alerts'
      email_configs:
      - to: 'oncall@codet.com'
        subject: 'PRODUCTION: YugabyteDB Alert'
        body: |
          PRODUCTION ALERT
          Alert: {{ .GroupLabels.alertname }}
          Description: {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
      webhook_configs:
      - url: 'http://localhost:5001/webhook'
        send_resolved: true

---
# AlertManager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:latest
        ports:
        - containerPort: 9093
        volumeMounts:
        - name: config-volume
          mountPath: /etc/alertmanager
        args:
        - '--config.file=/etc/alertmanager/alertmanager.yml'
        - '--storage.path=/alertmanager'
        - '--web.external-url=http://localhost:9093'
      volumes:
      - name: config-volume
        configMap:
          name: alertmanager-config

---
# AlertManager Service
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  selector:
    app: alertmanager
  ports:
  - port: 9093
    targetPort: 9093
  type: ClusterIP 